{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 14404,
     "status": "ok",
     "timestamp": 1638633703578,
     "user": {
      "displayName": "葉之晴",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15384545674565013435"
     },
     "user_tz": -480
    },
    "id": "Pnnw5JqDYcuL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import jieba\n",
    "from gensim import corpora,models,similarities\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1638633703578,
     "user": {
      "displayName": "葉之晴",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15384545674565013435"
     },
     "user_tz": -480
    },
    "id": "SCpfaJdDwyIK"
   },
   "outputs": [],
   "source": [
    "train_path = \"/Users/jhihchingyeh/Final Project/Dataset/stage1/\"\n",
    "test_path = \"/Users/jhihchingyeh/Final Project/Dataset/stage2/\"\n",
    "\n",
    "train_txtpath = \"dataTrainComplete/\"\n",
    "test_txtpath = \"dataPublicComplete/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1638633703578,
     "user": {
      "displayName": "葉之晴",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15384545674565013435"
     },
     "user_tz": -480
    },
    "id": "8XgxsfvbwqIk"
   },
   "outputs": [],
   "source": [
    "# Read Data\n",
    "def read_text(path, txtpath):\n",
    "    # 1. txt\n",
    "    # Construct an empty dataframe to store txt data\n",
    "    df = pd.DataFrame(columns = [\"ID\", \"text\"])\n",
    "    k = 0\n",
    "    # Read txt and Store into df\n",
    "    for i in range(1402):\n",
    "        text = []\n",
    "        txt_name = str(i) + \".txt\"\n",
    "        txt_path = path + txtpath + txt_name\n",
    "        try:\n",
    "            f = open(txt_path, 'r')\n",
    "            text = f.read()\n",
    "            f.close\n",
    "            df.loc[k, 'ID'] = i\n",
    "            df.loc[k, 'text'] = text\n",
    "            k = k + 1\n",
    "        except:\n",
    "            pass\n",
    "    # Change to array\n",
    "    arr_df = np.array(df[\"text\"])\n",
    "\n",
    "\n",
    "    # 2. Keyword.xlsx\n",
    "    # Read excel\n",
    "    key_chem = pd.read_excel(path+\"Keywords/02chem.list.xlsx\", header=None, index_col=False)\n",
    "    key_crop = pd.read_excel(path+\"Keywords/02crop.list.xlsx\", header=None, index_col=False)\n",
    "    key_pest = pd.read_excel(path+\"Keywords/02pest.list.xlsx\", header=None, index_col=False)\n",
    "    # Merge them\n",
    "    frames = [key_chem, key_crop, key_pest]\n",
    "    keyword = pd.concat(frames, axis=0)\n",
    "    \n",
    "\n",
    "    # 3. Train Label.csv\n",
    "    # Test data does not have label\n",
    "    try: \n",
    "        label_path = path + \"TrainLabel.csv\"\n",
    "        label = pd.read_csv(label_path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return df, keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the keyword by the shortest synonym\n",
    "def replace_keyword(df, keyword):\n",
    "    # Make and sort keyword lists\n",
    "    sort_keyword_list = []\n",
    "    num_cols = keyword.shape[1]\n",
    "    for ind, row in keyword.iterrows():\n",
    "        temp = [x for x in list(row) if pd.isnull(x) == False]\n",
    "        temp.sort(key=len, reverse=True)\n",
    "        sort_keyword_list.append(temp)\n",
    "    sort_keyword_list = sorted(sort_keyword_list, key=lambda x: len(x[0]), reverse=True)\n",
    "    \n",
    "    # Replace the keyword by the shortest synonym\n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(sort_keyword_list)):\n",
    "            for k in sort_keyword_list[j][1:]:\n",
    "                key = str(k)\n",
    "                if key in df[\"text\"][i]:\n",
    "                    #print(key, sort_keyword_list[j][0])\n",
    "                    df[\"text\"][i] = df[\"text\"][i].replace(key, sort_keyword_list[j][0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1638633703579,
     "user": {
      "displayName": "葉之晴",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15384545674565013435"
     },
     "user_tz": -480
    },
    "id": "inJWz-E43V4I"
   },
   "outputs": [],
   "source": [
    "# jieba Dictionary\n",
    "def jieba_dict(df):\n",
    "    df[\"jieba\"] = None\n",
    "    for i in range(len(df)):\n",
    "        data_ = []\n",
    "        list_ = []\n",
    "        data_ = jieba.cut(df[\"text\"][i])\n",
    "        for j in data_:\n",
    "            list_.append(j)\n",
    "        df.loc[i,\"jieba\"] = list_\n",
    "    # Calculate the Frequency of Term\n",
    "    all_list = df['jieba'].values.tolist()\n",
    "    frequency = defaultdict(int)\n",
    "    for m in all_list:\n",
    "        for n in m:\n",
    "            frequency[n] += 1\n",
    "            \n",
    "    # Build the Dictionary\n",
    "    dictionary = corpora.Dictionary(all_list)\n",
    "    return df, all_list, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1638633703579,
     "user": {
      "displayName": "葉之晴",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15384545674565013435"
     },
     "user_tz": -480
    },
    "id": "y1gR-4yx4qWg"
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "def prediction(df, all_list, dictionary):\n",
    "    # Submission.csv\n",
    "    submission = pd.read_csv(train_path+\"submission_example.csv\")\n",
    "    m = 0\n",
    "    \n",
    "    # Calculate the similarity\n",
    "    for k in range(len(df)):\n",
    "        # Sparse Matrix\n",
    "        new_vec = dictionary.doc2bow(df[\"jieba\"][k])\n",
    "        corpus = [dictionary.doc2bow(i) for i in all_list]\n",
    "        tfidf = models.TfidfModel(corpus)\n",
    "        featureNUM = len(dictionary.token2id.keys())\n",
    "        index = similarities.SparseMatrixSimilarity(tfidf[corpus],num_features=featureNUM)\n",
    "        sim = index[tfidf[new_vec]]\n",
    "        # Similarity Probability\n",
    "        for s in range(len(sim)):\n",
    "            if (sim[s]<1)&(sim[s]>0.6) == True:\n",
    "                if (str(df[\"ID\"][k]) != str(df[\"ID\"][s])):\n",
    "                    #print(df[\"ID\"][k], df[\"ID\"][s])\n",
    "                    submission.loc[m, \"Test\"] = df[\"ID\"][k]\n",
    "                    submission.loc[m, \"Reference\"] = df[\"ID\"][s]\n",
    "                    m += 1\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 2003,
     "status": "ok",
     "timestamp": 1638633705577,
     "user": {
      "displayName": "葉之晴",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15384545674565013435"
     },
     "user_tz": -480
    },
    "id": "W0Wp73k2339T"
   },
   "outputs": [],
   "source": [
    "df, keyword = read_text(test_path, test_txtpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = replace_keyword(df, keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CdK68bWfeLz",
    "outputId": "a48cdea8-37b7-4737-d8ae-90dc5c274ddc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/2s/tlvgbrd16jx_vcmf7z8m3sbm0000gn/T/jieba.cache\n",
      "Loading model cost 0.416 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "df, all_list, dictionary = jieba_dict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "r-CI852x4ZQu"
   },
   "outputs": [],
   "source": [
    "submission = prediction(df, all_list, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>1349.0</td>\n",
       "      <td>1318.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>1353.0</td>\n",
       "      <td>1344.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>1398.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>1398.0</td>\n",
       "      <td>427.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>1398.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>528 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Test  Reference  Unnamed: 2  Unnamed: 3  Unnamed: 4  Unnamed: 5  \\\n",
       "0      13.0      410.0         NaN         NaN         NaN         NaN   \n",
       "1      24.0       31.0         NaN         NaN         NaN         NaN   \n",
       "2      24.0       50.0         NaN         NaN         NaN         NaN   \n",
       "3      24.0      489.0         NaN         NaN         NaN         NaN   \n",
       "4      24.0      499.0         NaN         NaN         NaN         NaN   \n",
       "..      ...        ...         ...         ...         ...         ...   \n",
       "523  1349.0     1318.0         NaN         NaN         NaN         NaN   \n",
       "524  1353.0     1344.0         NaN         NaN         NaN         NaN   \n",
       "525  1398.0      331.0         NaN         NaN         NaN         NaN   \n",
       "526  1398.0      427.0         NaN         NaN         NaN         NaN   \n",
       "527  1398.0      750.0         NaN         NaN         NaN         NaN   \n",
       "\n",
       "     Unnamed: 6  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  \n",
       "..          ...  \n",
       "523         NaN  \n",
       "524         NaN  \n",
       "525         NaN  \n",
       "526         NaN  \n",
       "527         NaN  \n",
       "\n",
       "[528 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(test_path+\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPNedq0f5PU9N4XuHJknGnt",
   "collapsed_sections": [],
   "name": "try_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
